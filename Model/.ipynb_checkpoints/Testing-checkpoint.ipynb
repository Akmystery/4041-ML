{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n",
      "Training and predicting models...\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkarmin/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.379544\tvalid_1's l2: 0.372718\n",
      "[100]\ttraining's l2: 0.373755\tvalid_1's l2: 0.368434\n",
      "[150]\ttraining's l2: 0.373125\tvalid_1's l2: 0.368328\n",
      "[200]\ttraining's l2: 0.372626\tvalid_1's l2: 0.368293\n",
      "[250]\ttraining's l2: 0.37222\tvalid_1's l2: 0.368268\n",
      "Early stopping, best iteration is:\n",
      "[241]\ttraining's l2: 0.372288\tvalid_1's l2: 0.368263\n",
      "mean_14_2017: 2000677.33\n",
      "mean_7_2017: 1654065.02\n",
      "mean_3_2017: 104993.12\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.389392\tvalid_1's l2: 0.398645\n",
      "[100]\ttraining's l2: 0.384718\tvalid_1's l2: 0.394489\n",
      "[150]\ttraining's l2: 0.384159\tvalid_1's l2: 0.394401\n",
      "[200]\ttraining's l2: 0.3837\tvalid_1's l2: 0.394414\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's l2: 0.384107\tvalid_1's l2: 0.394386\n",
      "mean_14_2017: 1926773.62\n",
      "mean_7_2017: 1131169.58\n",
      "mean_3_2017: 36941.93\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.41764\tvalid_1's l2: 0.434415\n",
      "[100]\ttraining's l2: 0.411823\tvalid_1's l2: 0.428316\n",
      "[150]\ttraining's l2: 0.411089\tvalid_1's l2: 0.428187\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's l2: 0.411308\tvalid_1's l2: 0.428158\n",
      "mean_14_2017: 2233148.39\n",
      "mean_7_2017: 1288278.14\n",
      "mean_3_2017: 23959.73\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.436192\tvalid_1's l2: 0.439757\n",
      "[100]\ttraining's l2: 0.430054\tvalid_1's l2: 0.435215\n",
      "[150]\ttraining's l2: 0.429398\tvalid_1's l2: 0.435272\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's l2: 0.430054\tvalid_1's l2: 0.435215\n",
      "mean_14_2017: 2606962.88\n",
      "mean_7_2017: 1443978.49\n",
      "mean_3_2017: 36083.52\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.465609\tvalid_1's l2: 0.463102\n",
      "[100]\ttraining's l2: 0.458508\tvalid_1's l2: 0.457931\n",
      "[150]\ttraining's l2: 0.457628\tvalid_1's l2: 0.457703\n",
      "[200]\ttraining's l2: 0.457044\tvalid_1's l2: 0.457663\n",
      "[250]\ttraining's l2: 0.45653\tvalid_1's l2: 0.457629\n",
      "[300]\ttraining's l2: 0.456069\tvalid_1's l2: 0.457626\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttraining's l2: 0.456396\tvalid_1's l2: 0.4576\n",
      "mean_14_2017: 2818694.56\n",
      "mean_7_2017: 1237311.19\n",
      "mean_3_2017: 318890.16\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.437576\tvalid_1's l2: 0.44978\n",
      "[100]\ttraining's l2: 0.431921\tvalid_1's l2: 0.442872\n",
      "[150]\ttraining's l2: 0.4312\tvalid_1's l2: 0.442534\n",
      "[200]\ttraining's l2: 0.430703\tvalid_1's l2: 0.442532\n",
      "[250]\ttraining's l2: 0.430244\tvalid_1's l2: 0.442495\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's l2: 0.430284\tvalid_1's l2: 0.442483\n",
      "mean_14_2017: 2320645.05\n",
      "mean_7_2017: 1100013.61\n",
      "mean_3_2017: 153082.27\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.43964\tvalid_1's l2: 0.525859\n",
      "[100]\ttraining's l2: 0.4344\tvalid_1's l2: 0.514231\n",
      "[150]\ttraining's l2: 0.433691\tvalid_1's l2: 0.513479\n",
      "[200]\ttraining's l2: 0.43316\tvalid_1's l2: 0.513338\n",
      "[250]\ttraining's l2: 0.432684\tvalid_1's l2: 0.513258\n",
      "[300]\ttraining's l2: 0.432261\tvalid_1's l2: 0.513292\n",
      "Early stopping, best iteration is:\n",
      "[264]\ttraining's l2: 0.432564\tvalid_1's l2: 0.513193\n",
      "mean_14_2017: 2125861.52\n",
      "mean_7_2017: 1023513.46\n",
      "mean_3_2017: 143631.89\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.440965\tvalid_1's l2: 0.501411\n",
      "[100]\ttraining's l2: 0.435628\tvalid_1's l2: 0.491895\n",
      "[150]\ttraining's l2: 0.434925\tvalid_1's l2: 0.49135\n",
      "[200]\ttraining's l2: 0.434404\tvalid_1's l2: 0.491348\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's l2: 0.434674\tvalid_1's l2: 0.491297\n",
      "mean_14_2017: 2305291.29\n",
      "mean_7_2017: 1116712.97\n",
      "mean_3_2017: 19938.29\n",
      "==================================================\n",
      "Step 9\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.432779\tvalid_1's l2: 0.476668\n",
      "[100]\ttraining's l2: 0.428159\tvalid_1's l2: 0.47166\n",
      "[150]\ttraining's l2: 0.427525\tvalid_1's l2: 0.471488\n",
      "[200]\ttraining's l2: 0.427039\tvalid_1's l2: 0.471479\n",
      "[250]\ttraining's l2: 0.426638\tvalid_1's l2: 0.471492\n",
      "Early stopping, best iteration is:\n",
      "[235]\ttraining's l2: 0.426757\tvalid_1's l2: 0.47145\n",
      "mean_14_2017: 1994469.93\n",
      "mean_7_2017: 944712.81\n",
      "mean_3_2017: 19369.32\n",
      "==================================================\n",
      "Step 10\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.458929\tvalid_1's l2: 0.491147\n",
      "[100]\ttraining's l2: 0.453211\tvalid_1's l2: 0.486448\n",
      "[150]\ttraining's l2: 0.452402\tvalid_1's l2: 0.486412\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's l2: 0.452704\tvalid_1's l2: 0.486378\n",
      "mean_14_2017: 2238146.28\n",
      "mean_7_2017: 1094785.17\n",
      "mean_3_2017: 23117.66\n",
      "==================================================\n",
      "Step 11\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.483617\tvalid_1's l2: 0.488921\n",
      "[100]\ttraining's l2: 0.477944\tvalid_1's l2: 0.485975\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's l2: 0.478335\tvalid_1's l2: 0.485926\n",
      "mean_14_2017: 2582256.84\n",
      "mean_7_2017: 1217826.88\n",
      "mean_3_2017: 19764.83\n",
      "==================================================\n",
      "Step 12\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.511246\tvalid_1's l2: 0.520646\n",
      "[100]\ttraining's l2: 0.50462\tvalid_1's l2: 0.517296\n",
      "[150]\ttraining's l2: 0.50379\tvalid_1's l2: 0.517168\n",
      "[200]\ttraining's l2: 0.503211\tvalid_1's l2: 0.517089\n",
      "[250]\ttraining's l2: 0.502685\tvalid_1's l2: 0.516932\n",
      "[300]\ttraining's l2: 0.502227\tvalid_1's l2: 0.516895\n",
      "[350]\ttraining's l2: 0.501795\tvalid_1's l2: 0.516866\n",
      "[400]\ttraining's l2: 0.501414\tvalid_1's l2: 0.51683\n",
      "[450]\ttraining's l2: 0.50103\tvalid_1's l2: 0.516869\n",
      "Early stopping, best iteration is:\n",
      "[401]\ttraining's l2: 0.501404\tvalid_1's l2: 0.516821\n",
      "mean_14_2017: 2743374.39\n",
      "mean_7_2017: 1160010.98\n",
      "mean_3_2017: 210005.42\n",
      "==================================================\n",
      "Step 13\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.476167\tvalid_1's l2: 0.481781\n",
      "[100]\ttraining's l2: 0.470611\tvalid_1's l2: 0.478683\n",
      "[150]\ttraining's l2: 0.469836\tvalid_1's l2: 0.478626\n",
      "[200]\ttraining's l2: 0.46929\tvalid_1's l2: 0.478596\n",
      "[250]\ttraining's l2: 0.468809\tvalid_1's l2: 0.478527\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's l2: 0.46888\tvalid_1's l2: 0.478521\n",
      "mean_14_2017: 2300223.42\n",
      "mean_7_2017: 1001470.86\n",
      "mean_3_2017: 119103.51\n",
      "==================================================\n",
      "Step 14\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.473928\tvalid_1's l2: 0.474487\n",
      "[100]\ttraining's l2: 0.468835\tvalid_1's l2: 0.471552\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's l2: 0.468913\tvalid_1's l2: 0.471536\n",
      "mean_14_2017: 2098208.09\n",
      "mean_7_2017: 931429.62\n",
      "mean_3_2017: 105008.88\n",
      "==================================================\n",
      "Step 15\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.472989\tvalid_1's l2: 0.470667\n",
      "[100]\ttraining's l2: 0.467746\tvalid_1's l2: 0.467819\n",
      "[150]\ttraining's l2: 0.46701\tvalid_1's l2: 0.467779\n",
      "[200]\ttraining's l2: 0.466443\tvalid_1's l2: 0.467841\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttraining's l2: 0.466773\tvalid_1's l2: 0.467777\n",
      "mean_14_2017: 2246274.84\n",
      "mean_7_2017: 1018288.32\n",
      "mean_3_2017: 19027.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Step 16\n",
      "==================================================\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.462167\tvalid_1's l2: 0.46715\n",
      "[100]\ttraining's l2: 0.457566\tvalid_1's l2: 0.463684\n",
      "[150]\ttraining's l2: 0.456893\tvalid_1's l2: 0.463613\n",
      "[200]\ttraining's l2: 0.456387\tvalid_1's l2: 0.4636\n",
      "[250]\ttraining's l2: 0.455942\tvalid_1's l2: 0.463605\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttraining's l2: 0.45609\tvalid_1's l2: 0.463574\n",
      "mean_14_2017: 1941288.70\n",
      "mean_7_2017: 871863.02\n",
      "mean_3_2017: 18216.73\n",
      "Validation mse: 0.45977480289411476\n",
      "Making submission...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"LGBM Starter\n",
    "\n",
    "This is watered-down version of one of my earlier scripts. \n",
    "Only very basic features are retained so hopefully it won't ruin the fun for you.\n",
    "\"\"\"\n",
    "from datetime import date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "    '../Data/train.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    dtype={'onpromotion': bool},\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],\n",
    "    skiprows=range(1, 66458909)  # 2016-01-01\n",
    ")\n",
    "\n",
    "df_test = pd.read_csv(\n",
    "    \"../Data/test.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")\n",
    "\n",
    "items = pd.read_csv(\n",
    "    \"../Data/items.csv\",\n",
    ").set_index(\"item_nbr\")\n",
    "\n",
    "df_2017 = df_train[df_train.date.isin(\n",
    "    pd.date_range(\"2017-05-31\", periods=7 * 11))].copy()\n",
    "del df_train\n",
    "\n",
    "promo_2017_train = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)\n",
    "promo_2017_train.columns = promo_2017_train.columns.get_level_values(1)\n",
    "promo_2017_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_2017_test.columns = promo_2017_test.columns.get_level_values(1)\n",
    "promo_2017_test = promo_2017_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_2017_train, promo_2017_test], axis=1)\n",
    "del promo_2017_test, promo_2017_train\n",
    "\n",
    "df_2017 = df_2017.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_2017.columns = df_2017.columns.get_level_values(1)\n",
    "\n",
    "items = items.reindex(df_2017.index.get_level_values(1))\n",
    "\n",
    "def get_timespan(df, dt, minus, periods):\n",
    "    return df[\n",
    "        pd.date_range(dt - timedelta(days=minus), periods=periods)\n",
    "    ]\n",
    "\n",
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"mean_3_2017\": get_timespan(df_2017, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_2017, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_2017, t2017, 14, 14).mean(axis=1).values,\n",
    "    })\n",
    "    if is_train:\n",
    "        y = df_2017[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X\n",
    "\n",
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 6, 21)\n",
    "X_l, y_l = [], []\n",
    "for i in range(4):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(\n",
    "        t2017 + delta\n",
    "    )\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l\n",
    "X_val, y_val = prepare_dataset(date(2017, 7, 26))\n",
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)\n",
    "\n",
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 2**5 - 1,\n",
    "    'objective': 'regression_l2',\n",
    "    'max_depth': 8,\n",
    "    'min_data_in_leaf': 50,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.75,\n",
    "    'bagging_fraction': 0.75,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 1000\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 4) * 0.25 + 1\n",
    "    )\n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1,\n",
    "        categorical_feature=cate_vars)\n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=50\n",
    "    )\n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))\n",
    "\n",
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_2017.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('nopromo.csv', float_format='%.4f', index=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
