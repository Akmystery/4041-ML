{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib as plp\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\n",
    "    '../Data/train_set.csv', usecols=[1, 2, 3, 4, 5],\n",
    "    converters={'unit_sales': lambda u: np.log1p(\n",
    "        float(u)) if float(u) > 0 else 0},\n",
    "    parse_dates=[\"date\"],dtype={'onpromotion': bool}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"../Data/test.csv\", usecols=[0, 1, 2, 3, 4],\n",
    "    dtype={'onpromotion': bool},\n",
    "    parse_dates=[\"date\"]  # , date_parser=parser\n",
    ").set_index(\n",
    "    ['store_nbr', 'item_nbr', 'date']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\n",
    "    \"../Data/items.csv\",\n",
    ").set_index(\"item_nbr\") #In order to give weight to item perishable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_train = df_train.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"onpromotion\"]].unstack(\n",
    "        level=-1).fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_train.columns = promo_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_test = df_test[[\"onpromotion\"]].unstack(level=-1).fillna(False)\n",
    "promo_test.columns = promo_test.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "promo_test = promo_test.reindex(promo_2017_train.index).fillna(False)\n",
    "promo_2017 = pd.concat([promo_train, promo_test], axis=1)\n",
    "del promo_test, promo_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['store_nbr', 'item_nbr', 'date']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c7b785d2a962>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m df_train = df_train.set_index(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m[\u001b[0m\u001b[0;34m\"store_nbr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"item_nbr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"unit_sales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         level=-1).fillna(0)\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   4154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4156\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['store_nbr', 'item_nbr', 'date']\""
     ]
    }
   ],
   "source": [
    "df_train = df_train.set_index(\n",
    "    [\"store_nbr\", \"item_nbr\", \"date\"])[[\"unit_sales\"]].unstack(\n",
    "        level=-1).fillna(0)\n",
    "df_train.columns = df_train.columns.get_level_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.reindex(df_train.index.get_level_values(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timespan(df, dt, minus, periods):\n",
    "    return df[\n",
    "        pd.date_range(dt - timedelta(days=minus), periods=periods)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(t2017, is_train=True):\n",
    "    X = pd.DataFrame({\n",
    "        \"mean_3_2017\": get_timespan(df_train, t2017, 3, 3).mean(axis=1).values,\n",
    "        \"mean_7_2017\": get_timespan(df_train, t2017, 7, 7).mean(axis=1).values,\n",
    "        \"mean_14_2017\": get_timespan(df_train, t2017, 14, 14).mean(axis=1).values,\n",
    "        \"mean_16_2017\": get_timespan(df_train, t2017, 16, 16).mean(axis=1).values,\n",
    "        \"promo_14_2017\": get_timespan(promo_2017, t2017, 14, 14).sum(axis=1).values  \n",
    "    })\n",
    "    for i in range(16):\n",
    "        X[\"promo_{}\".format(i)] = promo_2017[t2017 + timedelta(days=i)].values.astype(np.uint8)\n",
    "    if is_train:\n",
    "        y = df_train[\n",
    "            pd.date_range(t2017, periods=16)\n",
    "        ].values\n",
    "        return X, y\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing dataset...\")\n",
    "t2017 = date(2017, 5, 16)\n",
    "X_l, y_l = [], []\n",
    "for i in range(9):\n",
    "    delta = timedelta(days=7 * i)\n",
    "    X_tmp, y_tmp = prepare_dataset(t2017 + delta)\n",
    "    X_l.append(X_tmp)\n",
    "    y_l.append(y_tmp)\n",
    "X_train = pd.concat(X_l, axis=0)\n",
    "y_train = np.concatenate(y_l, axis=0)\n",
    "del X_l, y_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = prepare_dataset(date(2017, 7, 23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = prepare_dataset(date(2017, 8, 16), is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and predicting models...\n",
      "==================================================\n",
      "Step 1\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkarmin/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.446218\tvalid_1's l2: 0.577263\n",
      "[100]\ttraining's l2: 0.355342\tvalid_1's l2: 0.457986\n",
      "[150]\ttraining's l2: 0.341092\tvalid_1's l2: 0.432492\n",
      "[200]\ttraining's l2: 0.337355\tvalid_1's l2: 0.424829\n",
      "[250]\ttraining's l2: 0.335835\tvalid_1's l2: 0.421992\n",
      "[300]\ttraining's l2: 0.334911\tvalid_1's l2: 0.420669\n",
      "[350]\ttraining's l2: 0.334195\tvalid_1's l2: 0.419768\n",
      "[400]\ttraining's l2: 0.333731\tvalid_1's l2: 0.419385\n",
      "[450]\ttraining's l2: 0.333336\tvalid_1's l2: 0.419186\n",
      "[500]\ttraining's l2: 0.333009\tvalid_1's l2: 0.419049\n",
      "[550]\ttraining's l2: 0.332717\tvalid_1's l2: 0.418956\n",
      "[600]\ttraining's l2: 0.332424\tvalid_1's l2: 0.418879\n",
      "[650]\ttraining's l2: 0.332168\tvalid_1's l2: 0.4188\n",
      "[700]\ttraining's l2: 0.331926\tvalid_1's l2: 0.418756\n",
      "[750]\ttraining's l2: 0.33169\tvalid_1's l2: 0.41873\n",
      "Early stopping, best iteration is:\n",
      "[748]\ttraining's l2: 0.3317\tvalid_1's l2: 0.41873\n",
      "mean_7_2017: 8995277.11\n",
      "mean_14_2017: 6833645.58\n",
      "mean_16_2017: 2464744.25\n",
      "mean_3_2017: 1594690.75\n",
      "promo_0: 462220.22\n",
      "promo_14_2017: 270779.27\n",
      "promo_1: 40263.27\n",
      "promo_7: 27718.71\n",
      "promo_4: 20344.28\n",
      "promo_14: 19628.56\n",
      "promo_15: 12435.60\n",
      "promo_5: 11949.10\n",
      "promo_8: 9182.48\n",
      "promo_13: 7530.31\n",
      "promo_10: 7167.93\n",
      "promo_2: 6990.86\n",
      "promo_12: 6688.78\n",
      "promo_3: 6589.13\n",
      "promo_6: 5328.78\n",
      "promo_11: 4981.56\n",
      "promo_9: 4946.38\n",
      "==================================================\n",
      "Step 2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkarmin/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.45031\tvalid_1's l2: 0.486588\n",
      "[100]\ttraining's l2: 0.355294\tvalid_1's l2: 0.393491\n",
      "[150]\ttraining's l2: 0.340195\tvalid_1's l2: 0.377785\n",
      "[200]\ttraining's l2: 0.336444\tvalid_1's l2: 0.374277\n",
      "[250]\ttraining's l2: 0.334934\tvalid_1's l2: 0.372954\n",
      "[300]\ttraining's l2: 0.333964\tvalid_1's l2: 0.372072\n",
      "[350]\ttraining's l2: 0.333227\tvalid_1's l2: 0.371589\n",
      "[400]\ttraining's l2: 0.332755\tvalid_1's l2: 0.371225\n",
      "[450]\ttraining's l2: 0.332322\tvalid_1's l2: 0.371011\n",
      "[500]\ttraining's l2: 0.331948\tvalid_1's l2: 0.370739\n",
      "[550]\ttraining's l2: 0.331629\tvalid_1's l2: 0.370647\n",
      "[600]\ttraining's l2: 0.33135\tvalid_1's l2: 0.370542\n",
      "[650]\ttraining's l2: 0.33108\tvalid_1's l2: 0.370459\n",
      "[700]\ttraining's l2: 0.330794\tvalid_1's l2: 0.370331\n",
      "[750]\ttraining's l2: 0.330539\tvalid_1's l2: 0.37029\n",
      "[800]\ttraining's l2: 0.330312\tvalid_1's l2: 0.370242\n",
      "[850]\ttraining's l2: 0.330083\tvalid_1's l2: 0.3702\n",
      "[900]\ttraining's l2: 0.329855\tvalid_1's l2: 0.370155\n",
      "[950]\ttraining's l2: 0.329641\tvalid_1's l2: 0.370125\n",
      "[1000]\ttraining's l2: 0.329429\tvalid_1's l2: 0.370094\n",
      "[1050]\ttraining's l2: 0.329234\tvalid_1's l2: 0.370083\n",
      "[1100]\ttraining's l2: 0.329043\tvalid_1's l2: 0.370043\n",
      "[1150]\ttraining's l2: 0.328846\tvalid_1's l2: 0.370047\n",
      "Early stopping, best iteration is:\n",
      "[1122]\ttraining's l2: 0.328955\tvalid_1's l2: 0.370021\n",
      "mean_14_2017: 12021182.70\n",
      "mean_7_2017: 6182837.07\n",
      "mean_16_2017: 1809617.73\n",
      "promo_1: 785239.62\n",
      "mean_3_2017: 405390.33\n",
      "promo_14_2017: 295877.75\n",
      "promo_8: 73790.14\n",
      "promo_15: 42525.24\n",
      "promo_0: 39845.00\n",
      "promo_10: 20964.48\n",
      "promo_14: 20212.07\n",
      "promo_4: 13215.84\n",
      "promo_12: 10631.67\n",
      "promo_5: 9846.41\n",
      "promo_3: 9665.92\n",
      "promo_2: 9014.04\n",
      "promo_7: 5698.85\n",
      "promo_13: 4476.25\n",
      "promo_6: 4279.09\n",
      "promo_9: 4084.65\n",
      "promo_11: 3549.42\n",
      "==================================================\n",
      "Step 3\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkarmin/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.448752\tvalid_1's l2: 0.471356\n",
      "[100]\ttraining's l2: 0.370892\tvalid_1's l2: 0.381147\n",
      "[150]\ttraining's l2: 0.35834\tvalid_1's l2: 0.363748\n",
      "[200]\ttraining's l2: 0.355215\tvalid_1's l2: 0.359091\n",
      "[250]\ttraining's l2: 0.353777\tvalid_1's l2: 0.357196\n",
      "[300]\ttraining's l2: 0.352827\tvalid_1's l2: 0.35619\n",
      "[350]\ttraining's l2: 0.352194\tvalid_1's l2: 0.355797\n",
      "[400]\ttraining's l2: 0.351709\tvalid_1's l2: 0.355629\n",
      "[450]\ttraining's l2: 0.351325\tvalid_1's l2: 0.355373\n",
      "[500]\ttraining's l2: 0.35098\tvalid_1's l2: 0.355164\n",
      "[550]\ttraining's l2: 0.350675\tvalid_1's l2: 0.355052\n",
      "[600]\ttraining's l2: 0.350393\tvalid_1's l2: 0.35499\n",
      "[650]\ttraining's l2: 0.350111\tvalid_1's l2: 0.354936\n",
      "[700]\ttraining's l2: 0.349851\tvalid_1's l2: 0.354851\n",
      "[750]\ttraining's l2: 0.349603\tvalid_1's l2: 0.354837\n",
      "Early stopping, best iteration is:\n",
      "[732]\ttraining's l2: 0.349691\tvalid_1's l2: 0.354813\n",
      "mean_14_2017: 11391118.22\n",
      "mean_7_2017: 4327756.43\n",
      "mean_16_2017: 1087059.99\n",
      "promo_2: 379751.83\n",
      "mean_3_2017: 296023.40\n",
      "promo_14_2017: 223047.80\n",
      "promo_1: 39018.85\n",
      "promo_4: 38117.70\n",
      "promo_3: 27031.12\n",
      "promo_5: 23432.59\n",
      "promo_0: 20323.21\n",
      "promo_6: 15801.25\n",
      "promo_7: 11891.58\n",
      "promo_8: 11842.20\n",
      "promo_9: 9606.49\n",
      "promo_15: 9219.85\n",
      "promo_14: 6319.79\n",
      "promo_10: 5298.28\n",
      "promo_12: 4366.92\n",
      "promo_13: 2585.34\n",
      "promo_11: 2486.48\n",
      "==================================================\n",
      "Step 4\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkarmin/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.486003\tvalid_1's l2: 0.44576\n",
      "[100]\ttraining's l2: 0.392325\tvalid_1's l2: 0.357667\n",
      "[150]\ttraining's l2: 0.376752\tvalid_1's l2: 0.344888\n",
      "[200]\ttraining's l2: 0.372658\tvalid_1's l2: 0.342365\n",
      "[250]\ttraining's l2: 0.370944\tvalid_1's l2: 0.341754\n",
      "[300]\ttraining's l2: 0.369825\tvalid_1's l2: 0.341407\n",
      "[350]\ttraining's l2: 0.369084\tvalid_1's l2: 0.341289\n",
      "[400]\ttraining's l2: 0.368508\tvalid_1's l2: 0.341247\n",
      "[450]\ttraining's l2: 0.368039\tvalid_1's l2: 0.341235\n",
      "Early stopping, best iteration is:\n",
      "[422]\ttraining's l2: 0.368296\tvalid_1's l2: 0.341207\n",
      "mean_14_2017: 13412090.68\n",
      "mean_7_2017: 4979549.88\n",
      "mean_16_2017: 1225364.09\n",
      "promo_3: 634039.43\n",
      "mean_3_2017: 318899.83\n",
      "promo_14_2017: 288875.16\n",
      "promo_10: 59626.14\n",
      "promo_4: 48574.49\n",
      "promo_1: 38448.99\n",
      "promo_6: 28366.51\n",
      "promo_0: 27729.59\n",
      "promo_5: 26268.28\n",
      "promo_8: 20105.80\n",
      "promo_15: 17478.19\n",
      "promo_7: 15156.82\n",
      "promo_2: 14422.02\n",
      "promo_12: 13162.93\n",
      "promo_11: 12458.25\n",
      "promo_14: 9899.21\n",
      "promo_13: 6996.12\n",
      "promo_9: 6104.81\n",
      "==================================================\n",
      "Step 5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkarmin/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.514528\tvalid_1's l2: 0.498068\n",
      "[100]\ttraining's l2: 0.408919\tvalid_1's l2: 0.437246\n",
      "[150]\ttraining's l2: 0.392094\tvalid_1's l2: 0.435152\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's l2: 0.396288\tvalid_1's l2: 0.434858\n",
      "mean_16_2017: 10513354.43\n",
      "mean_14_2017: 9342257.40\n",
      "mean_3_2017: 1436832.56\n",
      "mean_7_2017: 1421024.72\n",
      "promo_4: 375631.89\n",
      "promo_14_2017: 201986.21\n",
      "promo_3: 38130.28\n",
      "promo_6: 36493.37\n",
      "promo_5: 32330.13\n",
      "promo_8: 22006.78\n",
      "promo_7: 17665.97\n",
      "promo_0: 16822.20\n",
      "promo_1: 15160.85\n",
      "promo_15: 6917.26\n",
      "promo_2: 6305.19\n",
      "promo_9: 6008.87\n",
      "promo_10: 4073.69\n",
      "promo_11: 3529.12\n",
      "promo_14: 1734.17\n",
      "promo_13: 389.99\n",
      "promo_12: 284.18\n",
      "==================================================\n",
      "Step 6\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkarmin/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.546287\tvalid_1's l2: 0.509997\n",
      "[100]\ttraining's l2: 0.433846\tvalid_1's l2: 0.425368\n",
      "[150]\ttraining's l2: 0.414874\tvalid_1's l2: 0.414361\n",
      "[200]\ttraining's l2: 0.409648\tvalid_1's l2: 0.412373\n",
      "[250]\ttraining's l2: 0.407214\tvalid_1's l2: 0.411403\n",
      "[300]\ttraining's l2: 0.405492\tvalid_1's l2: 0.410886\n",
      "[350]\ttraining's l2: 0.404221\tvalid_1's l2: 0.410698\n",
      "[400]\ttraining's l2: 0.403403\tvalid_1's l2: 0.410504\n",
      "[450]\ttraining's l2: 0.402771\tvalid_1's l2: 0.410348\n",
      "[500]\ttraining's l2: 0.402237\tvalid_1's l2: 0.410297\n",
      "[550]\ttraining's l2: 0.401777\tvalid_1's l2: 0.410233\n",
      "[600]\ttraining's l2: 0.40139\tvalid_1's l2: 0.410146\n",
      "[650]\ttraining's l2: 0.401024\tvalid_1's l2: 0.410103\n",
      "[700]\ttraining's l2: 0.400673\tvalid_1's l2: 0.410102\n",
      "[750]\ttraining's l2: 0.40034\tvalid_1's l2: 0.410128\n",
      "Early stopping, best iteration is:\n",
      "[743]\ttraining's l2: 0.400389\tvalid_1's l2: 0.410076\n",
      "mean_16_2017: 17910945.75\n",
      "mean_3_2017: 3890570.26\n",
      "mean_14_2017: 2467895.66\n",
      "promo_5: 406781.70\n",
      "mean_7_2017: 368431.30\n",
      "promo_14_2017: 223474.82\n",
      "promo_4: 59409.79\n",
      "promo_6: 52967.85\n",
      "promo_8: 50000.84\n",
      "promo_7: 45812.39\n",
      "promo_1: 31834.13\n",
      "promo_3: 29606.66\n",
      "promo_2: 21490.56\n",
      "promo_15: 20569.73\n",
      "promo_0: 19557.26\n",
      "promo_12: 16774.99\n",
      "promo_10: 13863.86\n",
      "promo_9: 12032.91\n",
      "promo_11: 9903.30\n",
      "promo_14: 9759.22\n",
      "promo_13: 8615.60\n",
      "==================================================\n",
      "Step 7\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkarmin/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.495007\tvalid_1's l2: 0.577602\n",
      "[100]\ttraining's l2: 0.405046\tvalid_1's l2: 0.468108\n",
      "[150]\ttraining's l2: 0.390468\tvalid_1's l2: 0.44595\n",
      "[200]\ttraining's l2: 0.386486\tvalid_1's l2: 0.439089\n",
      "[250]\ttraining's l2: 0.384655\tvalid_1's l2: 0.436434\n",
      "[300]\ttraining's l2: 0.38337\tvalid_1's l2: 0.435256\n",
      "[350]\ttraining's l2: 0.382453\tvalid_1's l2: 0.434695\n",
      "[400]\ttraining's l2: 0.381839\tvalid_1's l2: 0.434587\n",
      "[450]\ttraining's l2: 0.381367\tvalid_1's l2: 0.434391\n",
      "[500]\ttraining's l2: 0.380978\tvalid_1's l2: 0.434204\n",
      "[550]\ttraining's l2: 0.380612\tvalid_1's l2: 0.434043\n",
      "[600]\ttraining's l2: 0.380291\tvalid_1's l2: 0.433909\n",
      "[650]\ttraining's l2: 0.379982\tvalid_1's l2: 0.433901\n",
      "[700]\ttraining's l2: 0.379699\tvalid_1's l2: 0.433822\n",
      "[750]\ttraining's l2: 0.379393\tvalid_1's l2: 0.433899\n",
      "Early stopping, best iteration is:\n",
      "[706]\ttraining's l2: 0.379663\tvalid_1's l2: 0.433804\n",
      "mean_16_2017: 12722428.75\n",
      "mean_14_2017: 3528792.19\n",
      "mean_7_2017: 2399964.80\n",
      "mean_3_2017: 788957.03\n",
      "promo_6: 426612.46\n",
      "promo_14_2017: 226710.82\n",
      "promo_7: 80516.15\n",
      "promo_4: 75766.95\n",
      "promo_8: 54215.41\n",
      "promo_5: 31927.51\n",
      "promo_0: 25126.19\n",
      "promo_1: 24899.03\n",
      "promo_3: 21255.13\n",
      "promo_15: 18494.13\n",
      "promo_10: 15091.56\n",
      "promo_2: 12363.08\n",
      "promo_9: 11388.15\n",
      "promo_14: 10294.93\n",
      "promo_12: 9690.61\n",
      "promo_13: 8659.85\n",
      "promo_11: 7109.33\n",
      "==================================================\n",
      "Step 8\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arkarmin/anaconda3/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[50]\ttraining's l2: 0.481732\tvalid_1's l2: 0.665379\n",
      "[100]\ttraining's l2: 0.393951\tvalid_1's l2: 0.54527\n",
      "[150]\ttraining's l2: 0.379209\tvalid_1's l2: 0.517051\n",
      "[200]\ttraining's l2: 0.375079\tvalid_1's l2: 0.507819\n",
      "[250]\ttraining's l2: 0.373119\tvalid_1's l2: 0.504033\n",
      "[300]\ttraining's l2: 0.371833\tvalid_1's l2: 0.502087\n",
      "[350]\ttraining's l2: 0.370948\tvalid_1's l2: 0.501015\n",
      "[400]\ttraining's l2: 0.370313\tvalid_1's l2: 0.500557\n",
      "[450]\ttraining's l2: 0.36981\tvalid_1's l2: 0.50024\n",
      "[500]\ttraining's l2: 0.369393\tvalid_1's l2: 0.499893\n",
      "[550]\ttraining's l2: 0.369006\tvalid_1's l2: 0.499758\n",
      "[600]\ttraining's l2: 0.368691\tvalid_1's l2: 0.499617\n",
      "[650]\ttraining's l2: 0.368394\tvalid_1's l2: 0.499347\n",
      "[700]\ttraining's l2: 0.368096\tvalid_1's l2: 0.499145\n",
      "[750]\ttraining's l2: 0.367824\tvalid_1's l2: 0.499083\n",
      "[800]\ttraining's l2: 0.367565\tvalid_1's l2: 0.498945\n",
      "[850]\ttraining's l2: 0.367314\tvalid_1's l2: 0.498801\n",
      "[900]\ttraining's l2: 0.367086\tvalid_1's l2: 0.498734\n",
      "[950]\ttraining's l2: 0.366866\tvalid_1's l2: 0.498637\n",
      "[1000]\ttraining's l2: 0.366639\tvalid_1's l2: 0.498576\n",
      "[1050]\ttraining's l2: 0.366414\tvalid_1's l2: 0.498546\n",
      "[1100]\ttraining's l2: 0.366191\tvalid_1's l2: 0.498459\n",
      "[1150]\ttraining's l2: 0.365975\tvalid_1's l2: 0.498473\n",
      "Early stopping, best iteration is:\n",
      "[1113]\ttraining's l2: 0.366132\tvalid_1's l2: 0.498445\n",
      "mean_14_2017: 9215116.53\n",
      "mean_16_2017: 5775112.88\n",
      "mean_7_2017: 2907785.14\n",
      "promo_7: 735274.02\n",
      "mean_3_2017: 318036.53\n",
      "promo_14_2017: 225791.03\n",
      "promo_0: 111084.57\n",
      "promo_8: 78778.15\n",
      "promo_4: 74210.29\n",
      "promo_14: 68872.67\n",
      "promo_6: 42918.10\n",
      "promo_1: 36859.09\n",
      "promo_5: 27000.88\n",
      "promo_15: 25914.44\n",
      "promo_3: 19855.43\n",
      "promo_10: 18513.22\n",
      "promo_2: 12592.71\n",
      "promo_12: 10174.77\n",
      "promo_9: 9968.80\n",
      "promo_11: 7329.26\n",
      "promo_13: 6169.48\n"
     ]
    }
   ],
   "source": [
    "print(\"Training and predicting models...\")\n",
    "params = {\n",
    "    'num_leaves': 80,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 200,\n",
    "    'learning_rate': 0.02,\n",
    "    'feature_fraction': 0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 16\n",
    "}\n",
    "\n",
    "MAX_ROUNDS = 5000\n",
    "val_pred = []\n",
    "test_pred = []\n",
    "cate_vars = []\n",
    "for i in range(16):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Step %d\" % (i+1))\n",
    "    print(\"=\" * 50)\n",
    "    dtrain = lgb.Dataset(\n",
    "        X_train, label=y_train[:, i],\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=pd.concat([items[\"perishable\"]] * 9) * 0.25 + 1\n",
    "    )\n",
    "    \n",
    "    dval = lgb.Dataset(\n",
    "        X_val, label=y_val[:, i], reference=dtrain,\n",
    "        categorical_feature=cate_vars,\n",
    "        weight=items[\"perishable\"] * 0.25 + 1\n",
    "    )\n",
    "    \n",
    "    bst = lgb.train(\n",
    "        params, dtrain, num_boost_round=MAX_ROUNDS,\n",
    "        valid_sets=[dtrain, dval], early_stopping_rounds=50, verbose_eval=50\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\".join((\"%s: %.2f\" % x) for x in sorted(\n",
    "        zip(X_train.columns, bst.feature_importance(\"gain\")),\n",
    "        key=lambda x: x[1], reverse=True\n",
    "    )))\n",
    "    val_pred.append(bst.predict(\n",
    "        X_val, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "    test_pred.append(bst.predict(\n",
    "        X_test, num_iteration=bst.best_iteration or MAX_ROUNDS))\n",
    "\n",
    "print(\"Validation mse:\", mean_squared_error(\n",
    "    y_val, np.array(val_pred).transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making submission...\")\n",
    "y_test = np.array(test_pred).transpose()\n",
    "df_preds = pd.DataFrame(\n",
    "    y_test, index=df_train.index,\n",
    "    columns=pd.date_range(\"2017-08-16\", periods=16)\n",
    ").stack().to_frame(\"unit_sales\")\n",
    "df_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)\n",
    "\n",
    "submission = df_test[[\"id\"]].join(df_preds, how=\"left\").fillna(0)\n",
    "submission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, 1000)\n",
    "submission.to_csv('modified_weight_promo.csv', float_format='%.4f', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
